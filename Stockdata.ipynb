{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1eb5b02-3313-4eb0-8ae0-175fa6b48eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from pymongo import UpdateOne, errors\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "import logging\n",
    "\n",
    "# MongoDB setup\n",
    "client = MongoClient(\"mongodb+srv://koratpratik2001:3UTSYp6E2nlQixgW@cmpe272project.j7rxj.mongodb.net/?retryWrites=true&w=majority&appName=Cmpe272Project\")  # Replace with your MongoDB URI if different\n",
    "db = client[\"stock_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfdcc37d-a02e-4242-8a42-97f95269cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 09:05:27,405 [INFO] Fetching stock data for ticker: AAPL\n",
      "2024-11-01 09:05:27,861 [INFO] Fetched 253 records for ticker: AAPL\n",
      "2024-11-01 09:05:27,897 [INFO] Ensured index on Date field.\n",
      "2024-11-01 09:05:28,952 [INFO] Bulk insert completed for AAPL.\n",
      "2024-11-01 09:05:29,052 [INFO] Data for AAPL saved to the database.\n",
      "2024-11-01 09:05:29,052 [INFO] Fetching stock data for ticker: NVDA\n",
      "2024-11-01 09:05:29,523 [INFO] Fetched 253 records for ticker: NVDA\n",
      "2024-11-01 09:05:29,604 [INFO] Ensured index on Date field.\n",
      "2024-11-01 09:05:31,206 [INFO] Bulk insert completed for NVDA.\n",
      "2024-11-01 09:05:31,271 [INFO] Data for NVDA saved to the database.\n",
      "2024-11-01 09:05:31,272 [INFO] Fetching stock data for ticker: META\n",
      "2024-11-01 09:05:31,406 [INFO] Fetched 253 records for ticker: META\n",
      "2024-11-01 09:05:31,487 [INFO] Ensured index on Date field.\n",
      "2024-11-01 09:05:32,218 [INFO] Bulk insert completed for META.\n",
      "2024-11-01 09:05:32,284 [INFO] Data for META saved to the database.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"stock_data.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Function to fetch stock data from Yahoo Finance\n",
    "def fetch_stock_data(ticker: str):\n",
    "    logging.info(f\"Fetching stock data for ticker: {ticker}\")\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist = stock.history(period=\"1y\")\n",
    "\n",
    "    if hist.empty:\n",
    "        logging.warning(f\"No data found for ticker: {ticker}\")\n",
    "        return None, \"No data found for this ticker.\"\n",
    "\n",
    "    data = hist.reset_index().to_dict(orient='records')\n",
    "    logging.info(f\"Fetched {len(data)} records for ticker: {ticker}\")\n",
    "    return data, None\n",
    "\n",
    "# Ensure index for efficient updates\n",
    "def ensure_index_stock(collection):\n",
    "    \"\"\"Ensures that the collection has an index on 'Date' to optimize upsert performance.\"\"\"\n",
    "    try:\n",
    "        collection.create_index([(\"Date\", 1)], unique=True)\n",
    "        logging.info(\"Ensured index on Date field.\")\n",
    "    except errors.OperationFailure as e:\n",
    "        logging.error(f\"Error ensuring index on Date field: {e}\")\n",
    "\n",
    "# Insert stock data with duplicate avoidance and max_entries control\n",
    "def insert_stock_data(ticker: str, stock_data: list, max_entries: int = 500):\n",
    "    \"\"\"Insert new stock data into the database, keeping only the latest `max_entries`.\"\"\"\n",
    "    collection_stock = db[f\"stock_data_{ticker}\"]\n",
    "\n",
    "    # Ensure index on 'Date' for efficient upserts\n",
    "    ensure_index_stock(collection_stock)\n",
    "\n",
    "    # Date one year ago for filtering old data\n",
    "    one_year_ago = datetime.now() - timedelta(days=365)\n",
    "    collection_stock.delete_many({\"Date\": {\"$lt\": one_year_ago}})\n",
    "\n",
    "    # Prepare bulk operations to upsert data\n",
    "    operations = []\n",
    "    for data in stock_data:\n",
    "        # Parse Date to datetime object\n",
    "        data['Date'] = parser.parse(str(data['Date']))\n",
    "        data['ticker'] = ticker\n",
    "\n",
    "        # Prepare upsert operation\n",
    "        operations.append(\n",
    "            UpdateOne(\n",
    "                {\"Date\": data['Date']},\n",
    "                {\"$set\": data},\n",
    "                upsert=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Execute bulk write\n",
    "    if operations:\n",
    "        try:\n",
    "            collection_stock.bulk_write(operations, ordered=False)\n",
    "            logging.info(f\"Bulk insert completed for {ticker}.\")\n",
    "\n",
    "            # Retain only the latest `max_entries`\n",
    "            current_entries = list(collection_stock.find().sort(\"Date\", -1).limit(max_entries))\n",
    "\n",
    "            if len(current_entries) == max_entries:\n",
    "                oldest_date_to_keep = current_entries[-1][\"Date\"]\n",
    "                collection_stock.delete_many({\"Date\": {\"$lt\": oldest_date_to_keep}})\n",
    "                logging.info(f\"Trimmed old entries, keeping latest {max_entries} records.\")\n",
    "        except errors.BulkWriteError as bwe:\n",
    "            logging.error(f\"Bulk write error: {bwe.details}\")\n",
    "\n",
    "def save_stock_data(ticker: str, delete_previous: bool = False, max_entries: int = 500):\n",
    "    \"\"\"\n",
    "    Fetches and saves stock data for a given ticker. Deletes previous data if specified.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        delete_previous (bool): Whether to delete previous data for the ticker.\n",
    "        max_entries (int): Maximum number of entries to retain in the database.\n",
    "    \"\"\"\n",
    "    stock_data, error = fetch_stock_data(ticker)\n",
    "\n",
    "    if error:\n",
    "        logging.error(f\"Error: {error}\")\n",
    "        return\n",
    "\n",
    "    if not stock_data:\n",
    "        logging.warning(\"No stock data found.\")\n",
    "        return\n",
    "\n",
    "    # Insert data with max_entries limit\n",
    "    insert_stock_data(ticker, stock_data, max_entries=max_entries)\n",
    "    logging.info(f\"Data for {ticker} saved to the database.\")\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define your list of tickers\n",
    "    ticker_symbols = [\"AAPL\", \"NVDA\", \"META\"]  # Add other tickers as needed\n",
    "\n",
    "    # Loop through each ticker in the list and save data\n",
    "    for ticker_symbol in ticker_symbols:\n",
    "        save_stock_data(ticker_symbol, delete_previous=True, max_entries=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490b7c2-0e38-4123-8a80-0772b2221b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
